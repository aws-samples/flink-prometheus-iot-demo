package com.amazonaws.examples.flink.datagen;

import org.apache.flink.api.connector.source.SourceReaderContext;
import org.apache.flink.connector.datagen.source.GeneratorFunction;
import org.apache.flink.util.Preconditions;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.Serializable;
import java.util.function.BiFunction;

/**
 * Parallel GeneratorFunction distributing a range of key index across substasks.
 * <p>
 * Every source subtask generates records for a fixed range of key indexes.
 * Useful when you need to generate records strictly in order for each key.
 *
 * @param <OUT>
 */
public abstract class ParallelGeneratorFunction<OUT> implements GeneratorFunction<Long, OUT>, Serializable {
    private static final Logger LOG = LoggerFactory.getLogger(ParallelGeneratorFunction.class);

    private final int startKeyIndex;
    private final int endKeyIndex;
    private final BiFunction<Long, KeyIndexSplit, OUT> recordGenerator;

    // Split of key indexes, calculated at runtime based on the source parallelism and the subtask index
    private transient KeyIndexSplit keyIndexSplit;


    /**
     * Constructor
     *
     * @param recordGenerator function returning the generated record
     * @param startKeyIndex   Start key index generated by the source (included)
     * @param endKeyIndex     end key index generated by the source (excluded)
     */
    public ParallelGeneratorFunction(BiFunction<Long, KeyIndexSplit, OUT> recordGenerator, int startKeyIndex, int endKeyIndex) {
        Preconditions.checkArgument(startKeyIndex >= 0, "Start key index must be >= 0");
        Preconditions.checkArgument(endKeyIndex > startKeyIndex, "End key index must be > start key index");
        this.recordGenerator = recordGenerator;
        this.startKeyIndex = startKeyIndex;
        this.endKeyIndex = endKeyIndex;
        LOG.info("Parallel generator. startIndex: {}, endIndex: {}", startKeyIndex, endKeyIndex);
    }


    @Override
    public void open(SourceReaderContext readerContext) throws Exception {
        int sourceParallelism = readerContext.currentParallelism();
        int subtaskIndex = readerContext.getIndexOfSubtask();

        // Calculate the range of key indexes for this subtask
        int keysPerSubtask = (endKeyIndex - startKeyIndex) / sourceParallelism;
        int subtaskStartKeyIndex = subtaskIndex * keysPerSubtask;
        int subtaskEndKeyIndex = subtaskStartKeyIndex + keysPerSubtask;

        // If this is the last subtask, add the remainder, if the key range is not divisible by the number of subtasks
        if (subtaskIndex == sourceParallelism - 1) {
            subtaskEndKeyIndex += (endKeyIndex - startKeyIndex) % sourceParallelism;
        }

        keyIndexSplit = new KeyIndexSplit(subtaskStartKeyIndex, subtaskEndKeyIndex);
    }

    @Override
    public final OUT map(Long value) throws Exception {
        return recordGenerator.apply(value, keyIndexSplit);
    }


    /**
     * A split of key indexes, wrapping the start index (included) and end index (excluded)
     * of a key split.
     */
    public static class KeyIndexSplit implements Serializable {

        private final int startKeyIndex;
        private final int endKeyIndex;

        public KeyIndexSplit(int startKeyIndex, int endKeyIndex) {
            this.startKeyIndex = startKeyIndex;
            this.endKeyIndex = endKeyIndex;
        }

        public int getStartKeyIndex() {
            return startKeyIndex;
        }

        public int getEndKeyIndex() {
            return endKeyIndex;
        }

        public int size() {
            return endKeyIndex - startKeyIndex;
        }
    }
}
